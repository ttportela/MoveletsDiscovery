{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length to consider\n",
    "sequences = [1]\n",
    "\n",
    "folder = './datasets/\n",
    "\n",
    "datasets = ['generic_nyc']\n",
    "\n",
    "# Indicates the column from each dataset to be analysed\n",
    "dd = {'generic_nyc_poi-hour': 'poi-hour'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to multiple datasets\n",
    "# datasets = ['d_1', 'd_2']\n",
    "# dd = {'d_1': c_1', 'd_2': 'c_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(core_name, x_train, x_test, y_train, y_test):\n",
    "    df_x_train = pd.DataFrame(x_train).to_csv(core_name+'-x_train.csv', index=False, header=None)\n",
    "    df_x_test = pd.DataFrame(x_test).to_csv(core_name+'-x_test.csv', index=False, header=None)\n",
    "    df_y_train = pd.DataFrame(y_train, columns=['label']).to_csv(core_name+'-y_train.csv', index=False)\n",
    "    df_y_test = pd.DataFrame(y_test, columns=['label']).to_csv(core_name+'-y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI-F: POI Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poi(df_train, df_test, possible_sequences, seq2idx):\n",
    "    \n",
    "    print('Starting POI...')\n",
    "    method = 'poi'\n",
    "    \n",
    "    # Train\n",
    "    train_tids = df_train['tid'].unique()\n",
    "    x_train = np.zeros((len(train_tids), len(possible_sequences)))\n",
    "    y_train = df_train.drop_duplicates(subset=['tid', 'label'],\n",
    "                                       inplace=False) \\\n",
    "                      .sort_values('tid', ascending=True,\n",
    "                                   inplace=False)['label'].values\n",
    "\n",
    "    for i, tid in enumerate(train_tids):\n",
    "        traj_pois = df_train[df_train['tid'] == tid][feature].values\n",
    "        for idx in range(0, (len(traj_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(traj_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            x_train[i][seq2idx[aux]] += 1\n",
    "\n",
    "    # Test\n",
    "    test_tids = df_test['tid'].unique()\n",
    "    test_unique_features = df_test[feature].unique().tolist()\n",
    "    x_test = np.zeros((len(test_tids), len(possible_sequences)))\n",
    "    y_test = df_test.drop_duplicates(subset=['tid', 'label'],\n",
    "                                       inplace=False) \\\n",
    "                      .sort_values('tid', ascending=True,\n",
    "                                   inplace=False)['label'].values\n",
    "\n",
    "    for i, tid in enumerate(test_tids):\n",
    "        traj_pois = df_test[df_test['tid'] == tid][feature].values\n",
    "        for idx in range(0, (len(traj_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(traj_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            if aux in possible_sequences:\n",
    "                x_test[i][seq2idx[aux]] += 1\n",
    "    core_name = 'outputs/'+method+'_'+feature+'_'+str(sequence)+'_'+dataset\n",
    "    to_file(core_name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPOI-F: Normalized POI Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npoi(df_train, df_test, possible_sequences, seq2idx):\n",
    "    \n",
    "    print('Starting NPOI...')\n",
    "    method = 'npoi'\n",
    "    \n",
    "    # Train\n",
    "    train_tids = df_train['tid'].unique()\n",
    "    x_train = np.zeros((len(train_tids), len(possible_sequences)))\n",
    "    y_train = df_train.drop_duplicates(subset=['tid', 'label'],\n",
    "                                       inplace=False) \\\n",
    "                      .sort_values('tid', ascending=True,\n",
    "                                   inplace=False)['label'].values\n",
    "\n",
    "    for i, tid in enumerate(train_tids):\n",
    "        traj_pois = df_train[df_train['tid'] == tid][feature].values\n",
    "        for idx in range(0, (len(traj_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(traj_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            x_train[i][seq2idx[aux]] += 1\n",
    "        x_train[i] = x_train[i]/len(traj_pois)\n",
    "\n",
    "    # Test\n",
    "    test_tids = df_test['tid'].unique()\n",
    "    test_unique_features = df_test[feature].unique().tolist()\n",
    "    x_test = np.zeros((len(test_tids), len(possible_sequences)))\n",
    "    y_test = df_test.drop_duplicates(subset=['tid', 'label'],\n",
    "                                       inplace=False) \\\n",
    "                      .sort_values('tid', ascending=True,\n",
    "                                   inplace=False)['label'].values\n",
    "\n",
    "    for i, tid in enumerate(test_tids):\n",
    "        traj_pois = df_test[df_test['tid'] == tid][feature].values\n",
    "        for idx in range(0, (len(traj_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(traj_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            if aux in possible_sequences:\n",
    "                x_test[i][seq2idx[aux]] += 1\n",
    "        x_test[i] = x_test[i]/len(traj_pois)\n",
    "    core_name = 'outputs/'+method+'_'+feature+'_'+str(sequence)+'_'+dataset\n",
    "    to_file(core_name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WNPOI-F: Weighted Normalized POI Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnpoi(df_train, df_test, possible_sequences, seq2idx):\n",
    "    \n",
    "    print('Starting WNPOI...')    \n",
    "    method = 'wnpoi'\n",
    "    \n",
    "    train_labels = df_train['label'].unique()\n",
    "    weights = np.zeros(len(possible_sequences))\n",
    "    for label in train_labels:\n",
    "        aux_w = np.zeros(len(possible_sequences))\n",
    "        class_pois = df_train[df_train['label'] == label][feature].values\n",
    "        for idx in range(0, (len(class_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(class_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            seqidx = seq2idx[aux]\n",
    "            if aux_w[seqidx] == 0:\n",
    "                weights[seqidx] += 1\n",
    "                aux_w[seqidx] = 1\n",
    "    weights = np.log2(len(train_labels)/weights)\n",
    "    # Train\n",
    "    train_tids = df_train['tid'].unique()\n",
    "    x_train = np.zeros((len(train_tids), len(possible_sequences)))\n",
    "    y_train = df_train.drop_duplicates(subset=['tid', 'label'],\n",
    "                                       inplace=False) \\\n",
    "                      .sort_values('tid', ascending=True,\n",
    "                                   inplace=False)['label'].values\n",
    "\n",
    "    for i, tid in enumerate(train_tids):\n",
    "        traj_pois = df_train[df_train['tid'] == tid][feature].values\n",
    "        for idx in range(0, (len(traj_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(traj_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            x_train[i][seq2idx[aux]] += 1\n",
    "        x_train[i] = x_train[i]/len(traj_pois)\n",
    "        for w in range(0, len(possible_sequences)):\n",
    "            x_train[i][w] *= weights[w]\n",
    "\n",
    "    # Test\n",
    "    test_tids = df_test['tid'].unique()\n",
    "    test_unique_features = df_test[feature].unique().tolist()\n",
    "    x_test = np.zeros((len(test_tids), len(possible_sequences)))\n",
    "    y_test = df_test.drop_duplicates(subset=['tid', 'label'],\n",
    "                                       inplace=False) \\\n",
    "                      .sort_values('tid', ascending=True,\n",
    "                                   inplace=False)['label'].values\n",
    "\n",
    "    for i, tid in enumerate(test_tids):\n",
    "        traj_pois = df_test[df_test['tid'] == tid][feature].values\n",
    "        for idx in range(0, (len(traj_pois)-(sequence - 1))):\n",
    "            aux = []\n",
    "            for b in range (0, sequence):\n",
    "                aux.append(traj_pois[idx + b])\n",
    "            aux = tuple(aux)\n",
    "            if aux in possible_sequences:\n",
    "                x_test[i][seq2idx[aux]] += 1\n",
    "        x_test[i] = x_test[i]/len(traj_pois)\n",
    "        for w in range(0, len(possible_sequences)):\n",
    "            x_test[i][w] *= weights[w]\n",
    "            \n",
    "    core_name = 'outputs/'+method+'_'+feature+'_'+str(sequence)+'_'+dataset+'_grrr'\n",
    "    to_file(core_name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all(sequence, dataset, feature, folder):\n",
    "    print('Dataset: {}, Feature: {}, Sequence: {}'.format(dataset, feature, sequence))\n",
    "    df_train = pd.read_csv(folder+dataset+'_train.csv')\n",
    "    df_test = pd.read_csv(folder+dataset+'_test.csv')\n",
    "    unique_features = df_train[feature].unique().tolist()\n",
    "    \n",
    "    points = df_train[feature].values\n",
    "    possible_sequences = []\n",
    "    for idx in range(0, (len(points)-(sequence - 1))):\n",
    "        aux = []\n",
    "        for i in range (0, sequence):\n",
    "            aux.append(points[idx + i])\n",
    "        aux = tuple(aux)\n",
    "        if aux not in possible_sequences:\n",
    "            possible_sequences.append(aux)\n",
    "\n",
    "    seq2idx = dict(zip(possible_sequences, np.r_[0:len(possible_sequences)]))\n",
    "    \n",
    "    poi(df_train, df_test, possible_sequences, seq2idx)\n",
    "    npoi(df_train, df_test, possible_sequences, seq2idx)\n",
    "    wnpoi(df_train, df_test, possible_sequences, seq2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: generic_nyc_poi-hour, Feature: poi-hour, Sequence: 1\n",
      "Starting WNPOI_SEQ...\n"
     ]
    }
   ],
   "source": [
    "for sequence in sequences:\n",
    "    for dataset in datasets:\n",
    "        feature = dd[dataset]\n",
    "        do_all(sequence, dataset, feature, folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
